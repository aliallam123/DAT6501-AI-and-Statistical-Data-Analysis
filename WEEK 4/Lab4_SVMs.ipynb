{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML5YoNrZS_Gc"
   },
   "source": [
    "# Week 4: Support Vector Machines and Optimisation\n",
    "\n",
    "The dataset and part of the exercises for this week were taken from MLPA.\n",
    "\n",
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Index: <a id='index'></a>\n",
    "1. [ATLAS experiment dataset](#atlas)\n",
    "2. [Linear Support Vector Machines](#linear)\n",
    "3. [Support Vector Machines Optimisation](#optimisation)\n",
    "4. [Feature engineering](#feature)\n",
    "5. [Nested cross validation](#nestedcv)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## ATLAS experiment dataset [^](#index) <a id='atlas'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with our usual imports, there are a few new ones from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "scz89F7WS_Ge"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import pandas.plotting as pdp\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder #This allows us to convert categorical features into integers\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate, cross_val_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV # New! This will be used to explore different hyperparameter choices.\n",
    "from sklearn.svm import SVC, LinearSVC # New algorithm!\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline #This allows one to build different steps together\n",
    "\n",
    "import UsedForMCQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below changes the output options of some of the pandas printout statements, it will make the columms more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "rc('text', usetex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5G8H8VDBS_Gu"
   },
   "source": [
    "You know the drill now, read in the dataset using `pandas` functionality, you may want to set `index_col='ID'`. Check that the dataframe was defined correctly using `head()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Xd7WnozpS_Gu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID       MET    METphi Type_1        P1        P2        P3        P4  \\\n",
      "0        0   62803.5 -1.810010      j  137571.0  128444.0 -0.345744 -0.307112   \n",
      "1        1   57594.2 -0.509253      j  161529.0   80458.3 -1.318010  1.402050   \n",
      "2        2   82313.3  1.686840      b  167130.0  113078.0  0.937258 -2.068680   \n",
      "3        3   30610.8  2.617120      j  112267.0   61383.9 -1.211050 -1.457800   \n",
      "4        4   45153.1 -2.241350      j  178174.0  100164.0  1.166880 -0.018721   \n",
      "...    ...       ...       ...    ...       ...       ...       ...       ...   \n",
      "4995  4995  269074.0 -1.274730      j  495577.0  362590.0 -0.791914  1.671250   \n",
      "4996  4996   12385.8  0.986871      j  258932.0  133559.0 -1.276540  2.970100   \n",
      "4997  4997   32762.8  3.057630      b  122222.0   79947.8  0.983920 -0.399231   \n",
      "4998  4998  104474.0 -1.875250      b  791028.0  457589.0  1.141530  2.934810   \n",
      "4999  4999   65623.8 -0.817535      b  145360.0  138746.0  0.236765  2.277120   \n",
      "\n",
      "     Type_2        P5        P6        P7        P8 Type_3         P9  \\\n",
      "0         j  174209.0  127932.0  0.826569  2.332000      b    86788.9   \n",
      "1         j  291490.0   68462.9 -2.126740 -2.582310     e-    44270.1   \n",
      "2         j  102423.0   54922.3  1.226850  0.646589      j    60768.9   \n",
      "3         b   40647.8   39472.0 -0.024646 -2.222800      j   201589.0   \n",
      "4         j   92351.3   69762.1  0.774114  2.568740      j    61625.2   \n",
      "...     ...       ...       ...       ...       ...    ...        ...   \n",
      "4995      b  328278.0  224827.0  0.922952 -1.284970      j  2628790.0   \n",
      "4996      j   87822.2   73895.0  0.604704 -0.646550      j   104199.0   \n",
      "4997      j  260623.0   49940.6  2.334630  0.555659      j    56696.1   \n",
      "4998      b  304661.0  224326.0  0.793147  0.407167      j   569714.0   \n",
      "4999      j  159680.0   42910.0 -1.987650 -0.873922      j   127125.0   \n",
      "\n",
      "           P10       P11       P12 Type_4       P13       P14       P15  \\\n",
      "0      84554.9 -0.180795  2.187970      j  140289.0   76955.8 -1.199330   \n",
      "1      35139.6 -0.706120 -0.371392     e+   72883.9   26902.2 -1.653860   \n",
      "2      36244.3  1.102890 -1.434480      j   77714.0   27801.5  1.684610   \n",
      "3      32978.6 -2.496040  1.137810      j   90096.7   26964.5  1.871320   \n",
      "4      50086.7  0.652572 -3.012800      j  104193.0   31151.0  1.876410   \n",
      "...        ...       ...       ...    ...       ...       ...       ...   \n",
      "4995  178652.0 -3.380790  2.922260      b  303713.0  156021.0 -1.284190   \n",
      "4996   67035.4 -1.003020 -0.909438      b   60343.9   38512.4 -1.013560   \n",
      "4997   49853.1  0.422515 -3.014610      j   36338.9   25777.1  0.850436   \n",
      "4998  151015.0  2.002460 -0.778558      j   83117.9   79371.7 -0.234668   \n",
      "4999   39118.8 -1.843890 -1.635370      b   44419.6   37225.8 -0.577472   \n",
      "\n",
      "           P16 Type_5       P17       P18       P19       P20 Type_6  \\\n",
      "0    -1.302800     m+   85230.6   70102.4 -0.645689 -1.659540    NaN   \n",
      "1    -3.129630    NaN       NaN       NaN       NaN       NaN    NaN   \n",
      "2     1.389690      j   26840.0   24469.3 -0.388937 -1.647260    NaN   \n",
      "3     0.817631      j   28235.4   25887.9 -0.411528  2.024290    NaN   \n",
      "4     0.865381      j  746585.0   26219.3  4.041820 -0.874169    NaN   \n",
      "...        ...    ...       ...       ...       ...       ...    ...   \n",
      "4995  0.436475      j  555572.0  116170.0  2.244670 -2.079480      j   \n",
      "4996  0.770876      j   55479.0   33020.8  1.101410  1.617520    NaN   \n",
      "4997  0.672009      j  262419.0   25037.1 -3.039990  2.820440    NaN   \n",
      "4998 -0.225965      j  374555.0   33465.4 -3.106010  1.426070      j   \n",
      "4999 -0.101245      j   55611.1   34467.7  1.057110  1.896630    NaN   \n",
      "\n",
      "           P21      P22       P23       P24 Type_7      P25      P26  \\\n",
      "0          NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "1          NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "2          NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "3          NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "4          NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "...        ...      ...       ...       ...    ...      ...      ...   \n",
      "4995  173426.0  64470.5  1.644410  2.545220      j  65465.9  53244.8   \n",
      "4996       NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "4997       NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "4998   31085.5  29817.5  0.290612  0.932758      j  37521.6  24471.5   \n",
      "4999       NaN      NaN       NaN       NaN    NaN      NaN      NaN   \n",
      "\n",
      "           P27       P28 Type_8       P29      P30       P31       P32 Type_9  \\\n",
      "0          NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "1          NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "2          NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "3          NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "4          NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "...        ...       ...    ...       ...      ...       ...       ...    ...   \n",
      "4995 -0.660150 -0.089563      j   47959.1  47171.9 -0.100525  2.179240      j   \n",
      "4996       NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "4997       NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "4998  0.955493 -1.282540     e-  122577.0  62144.7 -1.300900 -0.289339     m-   \n",
      "4999       NaN       NaN    NaN       NaN      NaN       NaN       NaN    NaN   \n",
      "\n",
      "           P33      P34      P35       P36 Type_10      P37      P38      P39  \\\n",
      "0          NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "1          NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "2          NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "3          NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "4          NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "...        ...      ...      ...       ...     ...      ...      ...      ...   \n",
      "4995  150048.0  23931.7  2.52114  1.527640       j  82489.5  23426.6  1.92712   \n",
      "4996       NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "4997       NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "4998  303878.0  49861.8  2.49372 -0.016383     NaN      NaN      NaN      NaN   \n",
      "4999       NaN      NaN      NaN       NaN     NaN      NaN      NaN      NaN   \n",
      "\n",
      "          P40 Type_11  P41  P42  P43  P44 Type_12  P45  P46  P47  P48 Type_13  \\\n",
      "0         NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "1         NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "2         NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "3         NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "4         NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "...       ...     ...  ...  ...  ...  ...     ...  ...  ...  ...  ...     ...   \n",
      "4995  1.00469     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "4996      NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "4997      NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "4998      NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "4999      NaN     NaN  NaN  NaN  NaN  NaN     NaN  NaN  NaN  NaN  NaN     NaN   \n",
      "\n",
      "      P49  P50  P51  P52  \n",
      "0     NaN  NaN  NaN  NaN  \n",
      "1     NaN  NaN  NaN  NaN  \n",
      "2     NaN  NaN  NaN  NaN  \n",
      "3     NaN  NaN  NaN  NaN  \n",
      "4     NaN  NaN  NaN  NaN  \n",
      "...   ...  ...  ...  ...  \n",
      "4995  NaN  NaN  NaN  NaN  \n",
      "4996  NaN  NaN  NaN  NaN  \n",
      "4997  NaN  NaN  NaN  NaN  \n",
      "4998  NaN  NaN  NaN  NaN  \n",
      "4999  NaN  NaN  NaN  NaN  \n",
      "\n",
      "[5000 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('ParticleID_features.csv')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data frame contains 67 features and 5000 instances (you can verify this with `shape`). \n",
    "\n",
    "The first two columns correspond to the magnitude (MET) and azimuthal angle (METphi) of the missing transverse energy vector.\n",
    "\n",
    "The other 65 features contain 5 descriptors (object type and energy quadrivector) for up to 13 particles observed in the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAl-0b3ES_Gv",
    "outputId": "3b896999-0a88-4101-e869-42ce0c14d3c8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show you how a different way of reading things work, I left the target labels in a separate file, that you can read using the line below. You may want to print `y` to verify that the reading worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "82IFUA9YS_Gv"
   },
   "outputs": [],
   "source": [
    "y = np.genfromtxt('ParticleID_labels.txt', dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A-Y9Mg5XS_Gv",
    "outputId": "0518e8db-5e1d-44c4-dbb5-1d500511eff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ttbar' 'ttbar' 'ttbar' ... 'ttbar' '4top' 'ttbar']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EQH55WhS_Gv"
   },
   "source": [
    "y represents an array of targets. What we want is '4top' events, our background corresponds to 'ttbar' events. This is a classification problem and you should know by now how it works.\n",
    "\n",
    "There is a problem though, which is that at the moment this is a categorical value (string-type) and we want to convert it to numerical form (e.g. 0/1).\n",
    "\n",
    "Use the `LabelEncoder()` `.fit_transform()` method to convert the categorical values to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lzB-AaSrS_Gv"
   },
   "outputs": [],
   "source": [
    "newy = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OQSG8hh7S_Gw",
    "outputId": "14e4c4ed-585a-405e-b59a-ab66f9d3f670"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transformer used 1 for the first instance, but we actually wanted 4top to be the positive label, so define `target` below to flip the labels of `newy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "t7WQyDGwS_Gx"
   },
   "outputs": [],
   "source": [
    "target = newy[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Wsr1pOy8S_Gx",
    "outputId": "a01e48ff-95e6-432a-e7a5-11e6a964f356"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target # Happier now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTJcgL79S_Gx"
   },
   "source": [
    "Let's take a look at these features, using the \"describe\" property. Note that this automatically excludes non-numerical type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asuEVhroS_Gy",
    "outputId": "178caa3d-71fc-4db0-c289-3156a303d355"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 1\n",
    "1. Size: What was the size of the data set?\n",
    "2. Missing data: count how many instances of missing data there are for every feature (only print out the non-zero ones).\n",
    "3. Write down different options on how to deal with the missing data. (There is no need to action them yet, we will do it together later).\n",
    "4. Balance: check how many `4top` events we have and compare that to the overall size of the dataset. What's the accuracy of a model that puts everything in the `ttbar` (ie negative) class? What's the accuracy of a random classifier?\n",
    "5. We have a trade-off between keeping more features but having a more severe missing data/imputing problem or keeping fewer features but dealing with a simpler imputing problem. We are choosing the latter. Define a new dataframe `feature_lim` that just includes the MET variables and the first 16 columns (first four particles).\n",
    "6. Count how many instances of missing data we now have for every feature, and use `.fillna` to replace the NaN values with 0s. (*Note: this is the simplest but worst possible choice - imputing a constant value skews the model :D One step up would be to input the mean or median for each column. However, because only a limited number of instances have missing data, the choice of imputing strategy doesn't matter too much*).\n",
    "7. Use the `scatter_matrix` function from `pandas.plotting` (already imported at the beginning of this notebook to display a scatter matrix of the first 6 features in the dataset). Comment on the shapes of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size was substantially big 1.4MB\n",
    "5000 rows x 68 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811\n"
     ]
    }
   ],
   "source": [
    "target\n",
    "count = 0\n",
    "\n",
    "for i in target:\n",
    "    if i == 0:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID            0\n",
      "MET           0\n",
      "METphi        0\n",
      "Type_1        0\n",
      "P1            0\n",
      "P2            0\n",
      "P3            0\n",
      "P4            0\n",
      "Type_2        3\n",
      "P5            3\n",
      "P6            3\n",
      "P7            3\n",
      "P8            3\n",
      "Type_3       50\n",
      "P9           50\n",
      "P10          50\n",
      "P11          50\n",
      "P12          50\n",
      "Type_4      283\n",
      "P13         283\n",
      "P14         283\n",
      "P15         283\n",
      "P16         283\n",
      "Type_5      998\n",
      "P17         998\n",
      "P18         998\n",
      "P19         998\n",
      "P20         998\n",
      "Type_6     2129\n",
      "P21        2129\n",
      "P22        2129\n",
      "P23        2129\n",
      "P24        2129\n",
      "Type_7     3111\n",
      "P25        3111\n",
      "P26        3111\n",
      "P27        3111\n",
      "P28        3111\n",
      "Type_8     3814\n",
      "P29        3814\n",
      "P30        3814\n",
      "P31        3814\n",
      "P32        3814\n",
      "Type_9     4271\n",
      "P33        4271\n",
      "P34        4271\n",
      "P35        4271\n",
      "P36        4271\n",
      "Type_10    4558\n",
      "P37        4558\n",
      "P38        4558\n",
      "P39        4558\n",
      "P40        4558\n",
      "Type_11    4739\n",
      "P41        4739\n",
      "P42        4739\n",
      "P43        4739\n",
      "P44        4739\n",
      "Type_12    4873\n",
      "P45        4873\n",
      "P46        4873\n",
      "P47        4873\n",
      "P48        4873\n",
      "Type_13    4944\n",
      "P49        4944\n",
      "P50        4944\n",
      "P51        4944\n",
      "P52        4944\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(features.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_L-a_R5S_Gy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV1hb_t2S_Gy",
    "outputId": "f3601d2c-6449-4fe3-fa7c-afc5d0849f36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-Lf0IDwS_Gz",
    "outputId": "47579686-b9af-4d2a-8354-4fe630c86c45",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZYyTYhrS_Gz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbnrvY0rS_G0",
    "outputId": "87922e80-d595-4dc9-da1b-34927e2ef184"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ve69kWKjS_G1"
   },
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Linear Supported Vector Machines  [^](#index) <a id='linear'></a>\n",
    "\n",
    "Linear Support Vector Machines (LinearSVC) offer a specific implementation for linear classification problems. The `C` stands for `Classifier` to distinguish them from the `Regression` models for SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ixh-JsVOS_G1"
   },
   "outputs": [],
   "source": [
    "bmodel = LinearSVC(dual = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dual` parameter controls whether the model solves the **primal** or **dual** formulation of the linear SVM optimisation problem. \n",
    "\n",
    "* **Primal formulation:** Optimises the objective function directly, focusing on finding the hyperplane that maximises the margin and minimises misclassification error.\n",
    "* **Dual formulation:** Introduces Lagrange multipliers and transforms the problem into a different form involving kernel functions. This can be more efficient for large datasets, especially with sparse data.\n",
    "\n",
    "* **`dual=False`:**\n",
    "    * Preferable when `n_samples > n_features` (more data points than features).\n",
    "    * Offers more interpretability, as the solution directly gives the weight vector (w) defining the hyperplane.\n",
    "    * Might be slower for large datasets.\n",
    "* **`dual=True`:**\n",
    "    * Preferable when `n_samples < n_features` (more features than data points).\n",
    "    * Can be faster for large datasets, especially with sparse data.\n",
    "    * Might be less interpretable, as the solution involves Lagrange multipliers instead of a direct weight vector.\n",
    "* **`dual=\"auto\"`:**\n",
    "    * Convenient option that automatically chooses based on data properties.\n",
    "    * Might not always be optimal, so consider manual selection based on your specific case.\n",
    "\n",
    "In our case we prefer `dual=False` as `n_samples > n_features`. If not, will not converge!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(UsedForMCQs.Q0)\n",
    "display(UsedForMCQs.Q00)\n",
    "display(UsedForMCQs.Q1)\n",
    "display(UsedForMCQs.Q2)\n",
    "display(UsedForMCQs.Q3)\n",
    "display(UsedForMCQs.Q4)\n",
    "display(UsedForMCQs.Q5)\n",
    "display(UsedForMCQs.Q6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 2\n",
    "1. Define a cross-validation strategy called `cv`, use the shuffled `StratifiedKFold` with 5 splits and `random_state=101` for reproducibility.\n",
    "2. Look at the class count to confirm it has worked as expected.\n",
    "3. Calculate the scores for the train and test scores from cross validation using `cross_validate` and `accuracy`. Find their mean and standard deviation. Comment on the model performance.\n",
    "4. Calculate the predicted labels and the confusion matrix, and comment on the performance of our first SVM classifier.\n",
    "5. Let's try to improve the performance applying with preprocessing our set with a scaler. Define a pipeline `piped_model` which uses the `StandardSclaer()` and LinearSVC(dual = False, C = 1000)`. Then repeat the cross validation procedure and discuss the performance looking at the cross validated test/train scores and the confusion matrix.\n",
    "6. Plot the learning curve for this pipeline using `cv = cv`, `train_sizes=np.array([0.05,0.1,0.2,0.5,1.0])` and `accuracy` as a score. Comment on the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvi2LG4YS_G1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QY7cAqlIS_G2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VscalT-S_G2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXgzxXWfS_G2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SaXQ-JkS_G2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X2EZ0t4S_G2",
    "outputId": "21e5de21-5560-4714-d5d2-3a0e8edcf1bf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnYkt7U7S_G4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2SvyIshS_G5"
   },
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Supported Vector Machines Optimisation [^](#index) <a id='optimisation'></a>\n",
    "The above model is our **benchmark**, we ran it without optimisation (with default parameters) and now would like to optimise it.\n",
    "\n",
    "When we optimise parameters with a grid search, we choose the parameters that give the best test scores. This is different from what would happen with new data - to do this fairly, at no point of the training procedure we are allowed to look at the test labels. Therefore, we would need to do **nested cross validation** to avoid leakage between the parameter optimisation and the cross validation procedure and properly evaluate the generalisation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNFoiueXS_G5",
    "outputId": "01da5aaf-c655-400b-e57b-0ee14a4066c6"
   },
   "outputs": [],
   "source": [
    "piped_model = make_pipeline(StandardScaler(), SVC()) #now using the general SVC so I can change the kernel\n",
    "\n",
    "piped_model.get_params() #this shows how we can access parameters both for the scaler and the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFPZcVTwS_G5"
   },
   "source": [
    "**We can define a dictionary of parameter values to run the optimisation.**\n",
    "\n",
    "How do we choose the parameters values?\n",
    "- Start with wide coverage (`gamma` and `C` might want to span several orders of magnitude)\n",
    "- If the best parameters are found at the edge of the grid, you might want to further expand the explored range of parameters\n",
    "- If the grid is too large, you can use `RandomSearchCV` instead which uses a random search.\n",
    "- In principle, you could use other techniques, like MCMC, to find the best combination. However, in my experience, excessive fine tuning of the parameters is usually rewarded with poor generalisation properties (ie high variance).\n",
    "\n",
    "Note that this might take a while (~3-5 mins); the early estimates output by this cell may be misleading because more complex models (in particular high gamma) take longer.\n",
    "\n",
    "Once you run this cell, the \"model\" object will have attributes \"best_score_\", \"best_params_\" and \"best_estimator_\", which give us access to the optimal estimator (printed out), as well as \"cv_results_\" that can be used to visualise the performance of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iaR-DhChS_G5",
    "outputId": "eb8c3d83-200d-489c-dbb8-92aabb77eb43"
   },
   "outputs": [],
   "source": [
    "#optimizing SVC: THIS IS NOT YET NESTED CV\n",
    "\n",
    "parameters = {'svc__kernel':['poly', 'rbf'], \\\n",
    "              'svc__gamma':[0.00001,'scale', 0.01, 0.1], 'svc__C':[0.1, 1.0, 10.0, 100.0], \\\n",
    "              'svc__degree': [2, 4, 8]}\n",
    "\n",
    "model = GridSearchCV(piped_model, parameters, cv = StratifiedKFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "\n",
    "model.fit(features_lim,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEfppjOGS_G6"
   },
   "source": [
    "#### Next, we visualize the models in a data frame, and rank them according to their test scores.\n",
    "\n",
    "I like to look at the mean and std of the test scores, the mean of the train scores (so I can evaluate if they differ and the significance of the result), and also fitting time (we may pick a faster model instead of the best model if the scores are comparable)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY_72jBHS_G7",
    "outputId": "a1ba6846-051c-48b8-f917-97db27f9b393"
   },
   "outputs": [],
   "source": [
    "scores_lim = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "scores_lim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lim[['params','mean_test_score','std_test_score','mean_train_score', \\\n",
    "            'mean_fit_time']].sort_values(by = 'mean_test_score', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build some intuition around the results, I find it helpful to ask: **what hyperparameter values are common to all the best-performing models?**\n",
    "\n",
    "Here, for example, the rbf kernel seems to be constantly preferred, while the values of C and gamma seem to only affect the scores only mildly. Note also that the Grid Search is insensitive to moot parameters combinations; for example, here the first three models are identical, because the degree of the polynomial kernel does not matter when using an rbf kernel. This is less than ideal, of course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2ICGBuTS_G6"
   },
   "source": [
    "#### We can also isolate one type of kernel to look at it more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6co-1HtsS_G6",
    "outputId": "d324bfc4-061c-40be-fa87-73edee0290fc"
   },
   "outputs": [],
   "source": [
    "scores_lim[scores_lim['param_svc__kernel'] == 'poly'][['params','mean_test_score','std_test_score',\\\n",
    "                        'mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiHw_EU-S_G7"
   },
   "source": [
    "### Final diagnosis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8lVS2-mS_HC"
   },
   "source": [
    "The problem here is high bias, which is not that surprising given that we are using only a subset of features.\n",
    "\n",
    "We can try two things: \n",
    "- using an imputing strategy to include information about the discarded features.\n",
    "- making up new features which might help, based on what we know about the problem.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(UsedForMCQs.Q7)\n",
    "display(UsedForMCQs.Q8)\n",
    "display(UsedForMCQs.Q9)\n",
    "display(UsedForMCQs.Q10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Feature engineering  [^](#index) <a id='feature'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prpkV4jgS_HC"
   },
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 3\n",
    "1. Let's go back to our original dataframe `features` and try using all of the features. Fill all NaN values with 0, and all empty categorical values with 0 too. (*Hint: for the second task you may want to use `.replace`*).\n",
    "2. Look at what kind of particles are produced in a collision. *Hint: you can do that by using `np.unique` on the values of the particle type features*. You should find 7 unique particles + the 0 for when there is no particle.\n",
    "3. **Feature engineering 1**: Calculate the total number of products of each type for example for b-jets:\n",
    "`nbtot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'b' for i in range(1,14)])) for j in range(features.shape[0])])`. Add the following new features to the dataframe:\n",
    "    1. The total number of particles produced `Total_products`\n",
    "    2. The total number of b jets `Total_b`\n",
    "    3. The total number of jets `Total_j`\n",
    "    4. The total number of leptons (electrons, positron, mu+, mu-) `Total_leptons`\n",
    "\n",
    "4. New define a new dataframe `features_lim_2` which contains the two MET variables, the 16 features of the first 4 products, and the total features we just calculated above.\n",
    "5. Define a pipeline `piped_model` which uses the `StandardScaler()` and `LinearSVC(dual = False)`. Then repeat the cross validation procedure and discuss the performance looking at the cross validated test/train scores, the confusion matrix, and the learning curve for `accuracy` like we did above. Comment on the results.\n",
    "6. Define a new pipeline `piped_model` using `StandardScaler()` and the general `SVC()` class so that you can optimise the model using a grid search of hyperparametes like we did above. Which is the best model and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcOdtWVUS_HG",
    "outputId": "1c99321f-982e-4e35-82c7-2b7b5f336c40"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1VSOK0QS_HG"
   },
   "source": [
    "### Another feature engineering attempt we could potentially do is use the type of product in the i-th location as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUP4q0o0S_HG"
   },
   "source": [
    "We could do it with label encoding, as we did earlier in this notebook, but such strategy introduces a notion of distance metric (labels that are mapped to 0 and 1 are interpreted to be closer to each other than labels that are mapped into 0 and 7). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcGC971kS_HG"
   },
   "source": [
    "As an alternative, we can introduce as many new columns as possible values for each categorical variable we are re-mapping, and we just use a 0/1 to indicate that the particle is of that type. This is achieved with the wonderfully-named \"get_dummies\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXVez-RVS_HH"
   },
   "outputs": [],
   "source": [
    "features_add = pd.get_dummies(data=features, columns=['Type_'+str(i) for i in range(1,14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmJWxmvSS_HH",
    "outputId": "297b6c72-97f7-4789-caf1-d87662246dd7"
   },
   "outputs": [],
   "source": [
    "features_add.columns[58:80] #A subset of the new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIKHO39vS_HH",
    "outputId": "da6cff62-ce52-4651-d8d5-6f1436d62f0f"
   },
   "outputs": [],
   "source": [
    "features_add.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8ttkdAIS_HH"
   },
   "source": [
    "**Feature engineering 2:** add other variables (type of product) for the first four particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3bi1jD-S_HH"
   },
   "outputs": [],
   "source": [
    "features_lim_3 = features_add[['MET', 'METphi', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11',\n",
    "       'P12',  'P13', 'P14', 'P15', 'P16','Total_products', 'Total_b' ,'Total_j','Total_g', \n",
    "              'Total_leptons','Type_1_b',\n",
    "       'Type_1_j', 'Type_2_0', 'Type_2_b', 'Type_2_e+', 'Type_2_e-',\n",
    "       'Type_2_g', 'Type_2_j', 'Type_2_m+', 'Type_2_m-', 'Type_3_0',\n",
    "       'Type_3_b', 'Type_3_e+', 'Type_3_e-', 'Type_3_g', 'Type_3_j',\n",
    "       'Type_3_m+', 'Type_3_m-', 'Type_4_0', 'Type_4_b', 'Type_4_e+',\n",
    "       'Type_4_e-', 'Type_4_g', 'Type_4_j', 'Type_4_m+', 'Type_4_m-']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "klZrsWyWS_HH",
    "outputId": "b98b1c8a-6d14-4b7e-f07d-1e31030a94ad"
   },
   "outputs": [],
   "source": [
    "features_lim_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 4\n",
    "1. Define a pipeline `piped_model` which uses the `StandardSclaer()` and `LinearSVC(dual = False)`. Then repeat the cross validation procedure on the new data frame `features_lim_3` and discuss the performance looking at the cross validated test/train scores, the confusion matrix, and the learning curve for `accuracy` like we did above. Comment on the results.\n",
    "2. Define a new pipeline `piped_model` using `StandardScaler()` and the general `SVC()` class so that you can optimise the model using a grid search of hyperparameters like we did above. Comment on the results.\n",
    "3. Define yet a new pipeline and run the cross validation procedure using all features (ie `features_add`). Discuss the performance looking at cross validates test/train scores, confusion matrix, and learning curve for `accuracy`. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2_MswU_S_HJ"
   },
   "source": [
    "<hr style=\"border:2px solid gray\">\n",
    "\n",
    "## Nested cross validation   <a id='nestedcv'></a> [^](#index)\n",
    "\n",
    "It is clear from our exploration that the model that performed best is the one using `features_lim_2`. Our `GridSearchCV` also gave us an idea of which parameters would be useful to further explore.\n",
    "\n",
    "Now we want to get an estimate of the generalisation error using **nested cross validation**. This can be computationally very expensive, so it's worth it to first select carefully the parameter grid we are going to explore. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(UsedForMCQs.Q11)\n",
    "display(UsedForMCQs.Q12)\n",
    "display(UsedForMCQs.Q13)\n",
    "display(UsedForMCQs.Q14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "## Exercise 5\n",
    "1. Define the hyperparameters for the nested cross validation based on the results of the hyperparameter searches above. Suggestion: use a number of parameters that results in less than 20 total combinations\n",
    "2. Define a `GridSearchCV` using these parameters and shuffled `StratifiedkFold` with 4 splits.\n",
    "3. Calculate the scores of nested cross validation using the `cross_val_score` function and a shuffled `StratifiedkFold` with 4 splits.\n",
    "4. Calculate the mean and standard deviation of the scores. Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
